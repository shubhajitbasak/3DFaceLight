Sep 13 2022 -

The number of training samples = 61225
epoch: 0 -> loss: 0.13002437353134155 -> running loss: 0.15870494395482293
epoch: 1 -> loss: 0.12153423577547073 -> running loss: 0.11666296928159652
epoch: 2 -> loss: 0.11252956837415695 -> running loss: 0.10717146372298603
epoch: 3 -> loss: 0.10901261121034622 -> running loss: 0.09946156537206673
epoch: 4 -> loss: 0.09776407480239868 -> running loss: 0.09155675085090335
epoch: 5 -> loss: 0.0872710794210434 -> running loss: 0.08277442371373081
epoch: 6 -> loss: 0.08248043805360794 -> running loss: 0.07507688909416152
epoch: 7 -> loss: 0.07440502196550369 -> running loss: 0.06757727925560338
epoch: 8 -> loss: 0.06976625323295593 -> running loss: 0.06099024643748086
epoch: 9 -> loss: 0.062482282519340515 -> running loss: 0.05417935004960571
epoch: 10 -> loss: 0.05725856497883797 -> running loss: 0.048348715904052035
epoch: 11 -> loss: 0.05360482633113861 -> running loss: 0.04384789788903096
epoch: 12 -> loss: 0.04939689114689827 -> running loss: 0.03980692030508307
epoch: 13 -> loss: 0.04492050036787987 -> running loss: 0.03677565609303821
epoch: 14 -> loss: 0.04281027242541313 -> running loss: 0.03426581571617142
epoch: 15 -> loss: 0.041961319744586945 -> running loss: 0.03224265991497546
epoch: 16 -> loss: 0.036736276000738144 -> running loss: 0.030420717385020633
epoch: 17 -> loss: 0.03611674904823303 -> running loss: 0.02854509040549026
epoch: 18 -> loss: 0.0329059436917305 -> running loss: 0.027003989424107755
epoch: 19 -> loss: 0.0332159586250782 -> running loss: 0.026021430481692243
epoch: 20 -> loss: 0.03305209055542946 -> running loss: 0.025136571551595915
epoch: 21 -> loss: 0.031084589660167694 -> running loss: 0.024340832454421268
epoch: 22 -> loss: 0.030450137332081795 -> running loss: 0.023621791272613164
epoch: 23 -> loss: 0.030315032228827477 -> running loss: 0.023100010602023466
epoch: 24 -> loss: 0.029841428622603416 -> running loss: 0.022662461710346138
epoch: 25 -> loss: 0.030564595013856888 -> running loss: 0.022255664995223856
epoch: 26 -> loss: 0.02853161096572876 -> running loss: 0.02178061808893368
epoch: 27 -> loss: 0.03044823184609413 -> running loss: 0.0214915924337067
epoch: 28 -> loss: 0.028698887676000595 -> running loss: 0.021243484461244244
epoch: 29 -> loss: 0.028537947684526443 -> running loss: 0.02085144168359983
epoch: 30 -> loss: 0.029498880729079247 -> running loss: 0.020626966695290967
epoch: 31 -> loss: 0.02956795133650303 -> running loss: 0.020371572409614635
epoch: 32 -> loss: 0.028680793941020966 -> running loss: 0.02017368212287501
epoch: 33 -> loss: 0.030192965641617775 -> running loss: 0.020036520258949066
epoch: 34 -> loss: 0.029637526720762253 -> running loss: 0.01997509678707847
epoch: 35 -> loss: 0.030638067051768303 -> running loss: 0.01984419161857708
epoch: 36 -> loss: 0.030100718140602112 -> running loss: 0.019785353394613892
epoch: 37 -> loss: 0.029629327356815338 -> running loss: 0.019648020975246094
epoch: 38 -> loss: 0.030924584716558456 -> running loss: 0.019643101565640232
epoch: 39 -> loss: 0.030615104362368584 -> running loss: 0.019693716305428596






***************************

